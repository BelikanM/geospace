import React, { useRef, useEffect, useState, useCallback } from 'react';
import Webcam from 'react-webcam';
import * as cocoSsd from '@tensorflow-models/coco-ssd';
import * as tf from '@tensorflow/tfjs';
import '@tensorflow/tfjs-backend-webgl';
import { motion, AnimatePresence } from 'framer-motion';
import { FaCamera, FaSave, FaInfoCircle, FaCog, FaExchangeAlt, FaVolumeUp, FaVolumeMute } from 'react-icons/fa';
import { BsZoomIn, BsZoomOut } from 'react-icons/bs';
import { MdPhotoLibrary } from 'react-icons/md';
import './Analyse.css';

// Base de donn√©es des objets enrichie
const objetInfos = {
  person: {
    icon: 'üë§',
    caracteristiques: "√ätre humain avec capacit√©s cognitives avanc√©es, dot√©e d'une structure bip√®de, d'expressions faciales et d'une posture verticale distinctive.",
    utilisation: "Interaction sociale, travail, cr√©ation artistique, recherche scientifique, sports, √©ducation.",
    categories: ["√™tre vivant", "mammif√®re"],
    materiaux: ["organique"],
    histoire: "L'√™tre humain moderne (Homo sapiens) existe depuis environ 300 000 ans.",
    conseil: "Respectez les personnes et leur espace personnel lors de vos prises de vue.",
    dimensionsMoyennes: { hauteur: "1.75m", largeur: "0.5m", profondeur: "0.25m" },
    poidsEstime: "70kg",
    textePotentiel: "V√™tements, accessoires, badges"
  },
  cell_phone: {
    icon: 'üì±',
    caracteristiques: "Appareil √©lectronique portable rectangulaire avec √©cran tactile, cam√©ras int√©gr√©es et diverses connectivit√©s sans fil.",
    utilisation: "Communication (appels, messages), navigation web, r√©seaux sociaux, photographie, vid√©o, jeux, applications diverses.",
    categories: ["√©lectronique", "communication"],
    materiaux: ["m√©tal", "verre", "plastique", "composants √©lectroniques"],
    histoire: "Le premier smartphone largement commercialis√© √©tait l'iPhone d'Apple en 2007.",
    conseil: "Prot√©gez votre t√©l√©phone avec une coque et un verre tremp√© pour prolonger sa dur√©e de vie.",
    dimensionsMoyennes: { hauteur: "15cm", largeur: "7cm", profondeur: "0.8cm" },
    poidsEstime: "170g",
    textePotentiel: "Marque, mod√®le, notifications √† l'√©cran"
  },
  cup: {
    icon: '‚òï',
    caracteristiques: "R√©cipient creux g√©n√©ralement cylindrique ou conique avec une anse, con√ßu pour contenir des liquides.",
    utilisation: "Boire des boissons chaudes ou froides comme le caf√©, le th√©, l'eau ou autres liquides.",
    categories: ["r√©cipient", "ustensile de cuisine"],
    materiaux: ["c√©ramique", "verre", "plastique", "m√©tal", "porcelaine"],
    histoire: "Les premi√®res tasses datent d'environ 10 000 ans avant J.-C., fabriqu√©es en argile.",
    conseil: "Les tasses en c√©ramique conservent mieux la chaleur des boissons chaudes.",
    dimensionsMoyennes: { hauteur: "10cm", diametre: "8cm" },
    poidsEstime: "300g",
    textePotentiel: "Logo, nom de marque, inscriptions d√©coratives"
  },
  chair: {
    icon: 'ü™ë',
    caracteristiques: "Meuble √† quatre pieds avec dossier, con√ßu pour permettre √† une personne de s'asseoir confortablement.",
    utilisation: "S'asseoir pour se reposer, manger, travailler, √©tudier ou socialiser.",
    categories: ["mobilier", "ameublement"],
    materiaux: ["bois", "m√©tal", "plastique", "tissu", "cuir"],
    histoire: "Les chaises existent depuis l'√âgypte ancienne, mais n'√©taient utilis√©es que par les personnes de haut rang.",
    conseil: "Une bonne chaise ergonomique peut pr√©venir les douleurs dorsales lors d'une utilisation prolong√©e.",
    dimensionsMoyennes: { hauteur: "85cm", largeur: "45cm", profondeur: "50cm" },
    poidsEstime: "5-10kg",
    textePotentiel: "Marque, √©tiquette de fabrication, code-barre"
  },
  laptop: {
    icon: 'üíª',
    caracteristiques: "Ordinateur portable avec clavier int√©gr√©, √©cran rabattable, touchpad et webcam.",
    utilisation: "Travail, jeux, navigation internet, programmation, design, montage vid√©o, √©ducation.",
    categories: ["√©lectronique", "informatique"],
    materiaux: ["aluminium", "plastique", "composants √©lectroniques", "verre"],
    histoire: "Le premier ordinateur portable commercial, l'Osborne 1, est apparu en 1981.",
    conseil: "Nettoyez r√©guli√®rement le clavier et les √©vents pour prolonger la dur√©e de vie de votre ordinateur portable.",
    dimensionsMoyennes: { hauteur: "1.5-2.5cm", largeur: "30-40cm", profondeur: "20-30cm" },
    poidsEstime: "1.2-2.5kg",
    textePotentiel: "Marque, mod√®le, autocollants, touches de clavier"
  },
  book: {
    icon: 'üìö',
    caracteristiques: "Ensemble de feuilles imprim√©es ou manuscrites reli√©es ensemble, contenant du texte et parfois des images.",
    utilisation: "Lecture, apprentissage, divertissement, r√©f√©rence, documentation.",
    categories: ["objet culturel", "m√©dia"],
    materiaux: ["papier", "carton", "encre", "colle", "fil"],
    histoire: "Les premiers livres imprim√©s datent de la Chine du 9√®me si√®cle, avec l'invention de l'imprimerie par Bi Sheng.",
    conseil: "Gardez vos livres √† l'abri de l'humidit√© et de la lumi√®re directe du soleil pour pr√©server leur √©tat.",
    dimensionsMoyennes: { hauteur: "20-30cm", largeur: "15-20cm", epaisseur: "1-5cm" },
    poidsEstime: "300-1000g",
    textePotentiel: "Titre, auteur, √©diteur, texte des pages"
  },
  bottle: {
    icon: 'üçæ',
    caracteristiques: "R√©cipient √©troit avec un goulot, souvent cylindrique, con√ßu pour stocker et servir des liquides.",
    utilisation: "Contenir et transporter des boissons ou liquides comme l'eau, le vin, l'huile ou produits cosm√©tiques.",
    categories: ["contenant", "r√©cipient"],
    materiaux: ["verre", "plastique", "m√©tal", "c√©ramique"],
    histoire: "Les bouteilles en verre sont utilis√©es depuis l'√©poque romaine, mais la production industrielle a commenc√© au 17√®me si√®cle.",
    conseil: "Les bouteilles r√©utilisables sont √©cologiques et √©conomiques √† long terme.",
    dimensionsMoyennes: { hauteur: "20-30cm", diametre: "5-10cm" },
    poidsEstime: "Vide: 100-500g, Pleine: 500-1500g",
    textePotentiel: "Marque, √©tiquette, informations nutritionnelles, volume"
  },
  keyboard: {
    icon: '‚å®Ô∏è',
    caracteristiques: "P√©riph√©rique d'entr√©e compos√© de touches organis√©es permettant la saisie de texte et commandes.",
    utilisation: "Saisie de texte, commandes informatiques, jeux vid√©o, programmation, communication √©crite.",
    categories: ["p√©riph√©rique", "informatique"],
    materiaux: ["plastique", "m√©tal", "composants √©lectroniques", "caoutchouc"],
    histoire: "Le clavier moderne QWERTY a √©t√© invent√© par Christopher Latham Sholes en 1868 pour les machines √† √©crire.",
    conseil: "Nettoyez r√©guli√®rement votre clavier pour √©liminer poussi√®re et d√©bris qui peuvent affecter son fonctionnement.",
    dimensionsMoyennes: { hauteur: "2-4cm", largeur: "30-45cm", profondeur: "12-18cm" },
    poidsEstime: "500-1200g",
    textePotentiel: "Touches, marque, mod√®le, indications fonctionnelles"
  },
  backpack: {
    icon: 'üéí',
    caracteristiques: "Sac √† dos port√© sur les √©paules avec des bretelles, comportant g√©n√©ralement plusieurs compartiments.",
    utilisation: "Transport de livres, ordinateurs, v√™tements, √©quipement de randonn√©e, fournitures scolaires.",
    categories: ["accessoire", "bagagerie"],
    materiaux: ["tissu", "nylon", "cuir", "polyester", "m√©tal (pour les fermetures)"],
    histoire: "Le sac √† dos moderne a √©t√© d√©velopp√© dans les ann√©es 1920 pour les activit√©s de plein air.",
    conseil: "R√©partissez le poids uniform√©ment et utilisez les deux bretelles pour √©viter les douleurs dorsales.",
    dimensionsMoyennes: { hauteur: "40-55cm", largeur: "30-40cm", profondeur: "15-30cm" },
    poidsEstime: "Vide: 500-1500g",
    textePotentiel: "Marque, logo, √©tiquettes de propri√©t√©"
  },
  couch: {
    icon: 'üõãÔ∏è',
    caracteristiques: "Meuble rembourr√© pour s'asseoir, avec dossier et accoudoirs, pouvant accueillir plusieurs personnes.",
    utilisation: "S'asseoir, se d√©tendre, regarder la t√©l√©vision, faire la sieste, socialiser.",
    categories: ["mobilier", "ameublement"],
    materiaux: ["bois", "tissu", "cuir", "mousse", "m√©tal"],
    histoire: "Le canap√© moderne remonte au 17√®me si√®cle en Europe, mais des meubles similaires existaient dans l'Antiquit√©.",
    conseil: "Tournez r√©guli√®rement les coussins pour assurer une usure uniforme et prolonger la dur√©e de vie du canap√©.",
    dimensionsMoyennes: { hauteur: "80-100cm", largeur: "180-250cm", profondeur: "80-120cm" },
    poidsEstime: "50-150kg",
    textePotentiel: "√âtiquette du fabricant, instructions d'entretien"
  },
  clock: {
    icon: 'üï∞Ô∏è',
    caracteristiques: "Instrument de mesure du temps avec cadran ou affichage num√©rique, m√©canisme interne et souvent aiguilles.",
    utilisation: "Mesure et affichage du temps, r√©veil, d√©coration.",
    categories: ["instrument", "d√©coration"],
    materiaux: ["m√©tal", "plastique", "verre", "bois", "composants √©lectroniques"],
    histoire: "Les premi√®res horloges m√©caniques sont apparues en Europe au 13√®me si√®cle.",
    conseil: "Les horloges traditionnelles n√©cessitent un remontage ou un changement de piles r√©gulier.",
    dimensionsMoyennes: { hauteur: "10-30cm", largeur: "10-30cm", profondeur: "3-10cm" },
    poidsEstime: "500-3000g",
    textePotentiel: "Chiffres, marque, indications horaires"
  },
  tv: {
    icon: 'üì∫',
    caracteristiques: "Appareil √©lectronique avec √©cran plat capable d'afficher des images et du son provenant de diverses sources.",
    utilisation: "Visionnage de programmes t√©l√©vis√©s, films, s√©ries, jeux vid√©o, pr√©sentation de contenus.",
    categories: ["√©lectronique", "multim√©dia"],
    materiaux: ["plastique", "verre", "composants √©lectroniques", "m√©tal"],
    histoire: "La premi√®re t√©l√©vision commerciale a √©t√© introduite dans les ann√©es 1920, mais la diffusion de masse a commenc√© apr√®s 1945.",
    conseil: "Maintenez une distance d'au moins 2.5 fois la diagonale de l'√©cran pour un confort visuel optimal.",
    dimensionsMoyennes: { hauteur: "40-80cm", largeur: "60-200cm", profondeur: "3-10cm" },
    poidsEstime: "5-50kg selon la taille",
    textePotentiel: "Marque, mod√®le, boutons d'interface, menus √† l'√©cran"
  },
  mouse: {
    icon: 'üñ±Ô∏è',
    caracteristiques: "P√©riph√©rique de pointage pour ordinateur, g√©n√©ralement avec au moins deux boutons et parfois une molette de d√©filement.",
    utilisation: "Navigation sur interface graphique, s√©lection, glisser-d√©poser, jeux vid√©o.",
    categories: ["p√©riph√©rique", "informatique"],
    materiaux: ["plastique", "composants √©lectroniques", "m√©tal"],
    histoire: "La premi√®re souris a √©t√© invent√©e par Douglas Engelbart en 1963 et pr√©sent√©e publiquement en 1968.",
    conseil: "Utilisez un tapis de souris pour am√©liorer la pr√©cision et prot√©ger la surface de votre bureau.",
    dimensionsMoyennes: { hauteur: "3-4cm", largeur: "6-8cm", longueur: "10-13cm" },
    poidsEstime: "80-150g",
    textePotentiel: "Marque, mod√®le, indications des boutons"
  },
  remote: {
    icon: 'üéÆ',
    caracteristiques: "Dispositif √©lectronique portatif avec boutons permettant de contr√¥ler un appareil √† distance.",
    utilisation: "Contr√¥le de t√©l√©viseurs, syst√®mes audio, climatiseurs, projecteurs et autres appareils √©lectroniques.",
    categories: ["√©lectronique", "contr√¥le"],
    materiaux: ["plastique", "caoutchouc", "composants √©lectroniques"],
    histoire: "Les premi√®res t√©l√©commandes pour t√©l√©viseurs sont apparues dans les ann√©es 1950.",
    conseil: "Nettoyez r√©guli√®rement votre t√©l√©commande, car elle peut accumuler beaucoup de bact√©ries avec l'utilisation.",
    dimensionsMoyennes: { hauteur: "1-2cm", largeur: "4-6cm", longueur: "15-20cm" },
    poidsEstime: "100-200g avec piles",
    textePotentiel: "Boutons num√©rot√©s, indications de fonctions, marque"
  },
  microwave: {
    icon: 'üì†',
    caracteristiques: "Appareil √©lectrom√©nager rectangulaire avec porte, panneau de contr√¥le et cavit√© interne pour chauffer les aliments.",
    utilisation: "R√©chauffage et cuisson rapide d'aliments par micro-ondes.",
    categories: ["√©lectrom√©nager", "cuisine"],
    materiaux: ["m√©tal", "plastique", "verre", "composants √©lectroniques"],
    histoire: "Le premier four √† micro-ondes commercial, le Radarange, a √©t√© lanc√© en 1947 par Raytheon.",
    conseil: "√âvitez de mettre des objets m√©talliques dans un micro-ondes en fonctionnement pour √©viter les arcs √©lectriques.",
    dimensionsMoyennes: { hauteur: "30-40cm", largeur: "45-60cm", profondeur: "30-45cm" },
    poidsEstime: "10-20kg",
    textePotentiel: "Marque, mod√®le, boutons de contr√¥le, indications de puissance"
  },
  umbrella: {
    icon: '‚òÇÔ∏è',
    caracteristiques: "Dispositif pliable avec toile tendue sur une armature pour prot√©ger de la pluie ou du soleil.",
    utilisation: "Protection contre les intemp√©ries (pluie, neige) et parfois contre le soleil.",
    categories: ["accessoire", "protection"],
    materiaux: ["tissu", "m√©tal", "plastique", "fibre de verre"],
    histoire: "Les parapluies existent depuis plus de 4000 ans, d'abord utilis√©s comme protection solaire en √âgypte et Chine anciennes.",
    conseil: "Laissez s√©cher votre parapluie ouvert apr√®s utilisation pour √©viter la moisissure et la rouille.",
    dimensionsMoyennes: { hauteur: "60-100cm (ferm√©)", diametre: "80-120cm (ouvert)" },
    poidsEstime: "300-800g",
    textePotentiel: "Marque, motifs d√©coratifs"
  }
};

/**
 * Simule le chargement d'un mod√®le d'IA personnalis√© en compl√©ment de COCO-SSD
 * @returns {Promise<boolean>} √âtat du chargement du mod√®le
 */
const loadCustomModel = async () => {
  console.log("Chargement du mod√®le personnalis√©...");
  await new Promise(resolve => setTimeout(resolve, 1000)); // Simulation de chargement
  console.log("Mod√®le personnalis√© charg√©");
  return true;
};

/**
 * Enrichit les pr√©dictions de l'IA avec des informations suppl√©mentaires
 * @param {Array} predictions - Pr√©dictions brutes du mod√®le COCO-SSD
 * @returns {Array} - Pr√©dictions enrichies avec donn√©es additionnelles
 */
const enrichPredictions = (predictions) => {
  return predictions.map(prediction => {
    const baseInfo = objetInfos[prediction.class] || {
      icon: '‚ùì',
      caracteristiques: "Informations non disponibles dans notre base de connaissances.",
      utilisation: "Utilisation non sp√©cifi√©e.",
      categories: ["non classifi√©"],
      materiaux: ["inconnu"],
      histoire: "Histoire non document√©e.",
      conseil: "Aucun conseil disponible.",
      dimensionsMoyennes: { notes: "Dimensions inconnues" },
      poidsEstime: "Inconnu",
      textePotentiel: "Texte inconnu"
    };
    
    const [x, y, width, height] = prediction.bbox;
    const aspectRatio = width / height;
    
    // Estimation de la taille r√©elle (approximative)
    let tailleEstimee = null;
    if (baseInfo.dimensionsMoyennes) {
      tailleEstimee = {
        ...baseInfo.dimensionsMoyennes,
        ratioImage: aspectRatio.toFixed(2),
        surface: `${(width * height).toFixed(0)} pixels¬≤`,
        proportionImage: `${((width * height) / (640 * 480) * 100).toFixed(1)}% de l'image`
      };
    }
    
    return {
      ...prediction,
      ...baseInfo,
      detectedAt: new Date().toISOString(),
      certainty: prediction.score > 0.8 ? "√âlev√©e" : prediction.score > 0.6 ? "Moyenne" : "Faible",
      dimensions: {
        pixels: { width: width.toFixed(0), height: height.toFixed(0) },
        estimationTailleReelle: tailleEstimee
      },
      analyseTexte: {
        potentiel: baseInfo.textePotentiel,
        zoneTexte: width > 100 && height > 30 ? "Zone suffisante pour contenir du texte" : "Zone probablement trop petite pour du texte lisible"
      }
    };
  });
};

/**
 * Analyse les dimensions et positions des objets d√©tect√©s dans l'image
 * @param {Object} prediction - Pr√©diction enrichie
 * @param {number} videoWidth - Largeur de la vid√©o
 * @param {number} videoHeight - Hauteur de la vid√©o
 * @returns {Object} - Analyse dimensionnelle compl√®te de l'objet
 */
const analyserDimensionsObjets = (prediction, videoWidth, videoHeight) => {
  const [x, y, width, height] = prediction.bbox;
  
  const proportionLargeur = width / videoWidth;
  const proportionHauteur = height / videoHeight;
  const proportionSurface = (width * height) / (videoWidth * videoHeight);
  
  // Estimation de distance bas√©e sur la taille relative
  let distanceEstimee = "ind√©termin√©e";
  if (proportionSurface > 0.5) distanceEstimee = "tr√®s proche";
  else if (proportionSurface > 0.25) distanceEstimee = "proche";
  else if (proportionSurface > 0.1) distanceEstimee = "distance moyenne";
  else if (proportionSurface > 0.05) distanceEstimee = "√©loign√©";
  else distanceEstimee = "tr√®s √©loign√©";
  
  return {
    proportionImage: {
      largeur: `${(proportionLargeur * 100).toFixed(1)}%`,
      hauteur: `${(proportionHauteur * 100).toFixed(1)}%`,
      surface: `${(proportionSurface * 100).toFixed(1)}%`
    },
    taillePixels: {
      largeur: Math.round(width),
      hauteur: Math.round(height),
      rapport: (width / height).toFixed(2)
    },
    distanceEstimee,
    dimensionsEstimees: prediction.dimensionsMoyennes || "Donn√©es non disponibles"
  };
};

/**
 * Composant principal d'analyse d'objets en temps r√©el
 */
const Analyse = () => {
  // R√©f√©rences
  const webcamRef = useRef(null);
  const canvasRef = useRef(null);
  const modelRef = useRef(null);
  const speechSynthesisRef = useRef(null);

  // √âtats
  const [predictions, setPredictions] = useState([]);
  const [isDetecting, setIsDetecting] = useState(true);
  const [selectedObject, setSelectedObject] = useState(null);
  const [cameraFacingMode, setCameraFacingMode] = useState("environment");
  const [capturedImage, setCapturedImage] = useState(null);
  const [showSettings, setShowSettings] = useState(false);
  const [zoomLevel, setZoomLevel] = useState(1);
  const [brightness, setBrightness] = useState(100);
  const [audioEnabled, setAudioEnabled] = useState(true);
  const [detectionMode, setDetectionMode] = useState("normal");
  const [loadingModel, setLoadingModel] = useState(true);
  const [errorMessage, setErrorMessage] = useState(null);
  const [darkMode, setDarkMode] = useState(window.matchMedia('(prefers-color-scheme: dark)').matches);
  const [enableCloudAnalysis, setEnableCloudAnalysis] = useState(false);
  const [objectAnalyses, setObjectAnalyses] = useState({});

  // R√©f√©rences pour optimisation
  const lastPredictionsRef = useRef([]);
  const lastDetectionTimeRef = useRef(0);
  const detectionInterval = detectionMode === "fast" ? 300 : detectionMode === "detail" ? 100 : 200; 
  
  // Appliquer le mode sombre
  useEffect(() => {
    document.body.classList.toggle('dark-mode', darkMode);
  }, [darkMode]);

  // Annuler toute synth√®se vocale en cours quand l'audio est d√©sactiv√©
  useEffect(() => {
    if (!audioEnabled) {
      window.speechSynthesis.cancel();
    }
  }, [audioEnabled]);

  // Charger le mod√®le
  useEffect(() => {
    const loadModel = async () => {
      try {
        setLoadingModel(true);
        
        // Assurer que TensorFlow.js utilise WebGL
        await tf.setBackend('webgl');
        console.log("Backend TensorFlow.js:", tf.getBackend());
        
        // Charger mod√®le COCO-SSD
        console.log("Chargement du mod√®le COCO-SSD...");
        const cocoModel = await cocoSsd.load({
          base: detectionMode === "fast" ? "lite_mobilenet_v2" : "mobilenet_v2"
        });
        
        // Charger le mod√®le personnalis√©
        const customModelLoaded = await loadCustomModel();
        
        // Stocker les r√©f√©rences
        modelRef.current = {
          cocoModel,
          customModelLoaded,
          createdAt: new Date()
        };
        
        setLoadingModel(false);
        
        // Message de bienvenue
        if (audioEnabled) {
          window.speechSynthesis.cancel(); // Annuler tout message en cours
          const speech = new SpeechSynthesisUtterance("Syst√®me d'analyse d'objets pr√™t √† l'emploi");
          window.speechSynthesis.speak(speech);
        }
      } catch (error) {
        console.error("Erreur lors du chargement des mod√®les:", error);
        setErrorMessage(`Impossible de charger les mod√®les d'IA. ${error.message || "Veuillez v√©rifier votre connexion internet et recharger l'application."}`);
        setLoadingModel(false);
      }
    };
    
    loadModel();
    
    return () => {
      // Nettoyage √† la fermeture
      window.speechSynthesis.cancel();
      console.log("Nettoyage des ressources...");
    };
  }, [detectionMode, audioEnabled]);
  
  /**
   * Fonction principale de d√©tection d'objets et dessin
   */
  const detectFrame = useCallback(async () => {
    // V√©rification des pr√©requis
    if (
      !isDetecting || 
      !modelRef.current?.cocoModel || 
      !webcamRef.current?.video || 
      webcamRef.current.video.readyState !== 4
    ) {
      requestAnimationFrame(detectFrame);
      return;
    }

    // Limiter la fr√©quence de d√©tection
    const now = performance.now();
    if (now - lastDetectionTimeRef.current < detectionInterval) {
      requestAnimationFrame(detectFrame);
      return;
    }
    lastDetectionTimeRef.current = now;

    try {
      const video = webcamRef.current.video;
      const canvas = canvasRef.current;
      
      if (!canvas) {
        requestAnimationFrame(detectFrame);
        return;
      }
      
      const ctx = canvas.getContext('2d');

      // Ajuster le canvas aux dimensions de la vid√©o
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;

      // D√©tection des objets
      const rawPredictions = await modelRef.current.cocoModel.detect(video, 10);
      
      // Filtrer par seuil de confiance et trier
      const filteredPredictions = rawPredictions
        .filter(prediction => prediction.score > 0.35)
        .sort((a, b) => b.score - a.score);
        
      // Enrichir les pr√©dictions
      const enhancedPredictions = enrichPredictions(filteredPredictions);
      
      // V√©rifier si changement significatif
      const lastPredClasses = lastPredictionsRef.current
        .map(p => `${p.class}-${p.score.toFixed(2)}`)
        .join(',');
      const newPredClasses = enhancedPredictions
        .map(p => `${p.class}-${p.score.toFixed(2)}`)
        .join(',');
      
      if (lastPredClasses !== newPredClasses) {
        // Mise √† jour des √©tats
        setPredictions(enhancedPredictions);
        lastPredictionsRef.current = enhancedPredictions;
        
        // Analyser les dimensions des objets
        const newAnalyses = {};
        enhancedPredictions.forEach(pred => {
          const objectId = `${pred.class}-${Math.random().toString(36).substring(2, 7)}`;
          newAnalyses[objectId] = {
            ...pred,
            analyseComplete: analyserDimensionsObjets(pred, video.videoWidth, video.videoHeight),
            horodatage: new Date().toISOString()
          };
        });
        
        setObjectAnalyses(prev => ({...prev, ...newAnalyses}));
        
        // Notification vocale pour la d√©tection principale
        if (audioEnabled && enhancedPredictions.length > 0 && enhancedPredictions[0].score > 0.7) {
          // Annuler toute synth√®se en cours
          window.speechSynthesis.cancel();
          
          const topPrediction = enhancedPredictions[0];
          const speech = new SpeechSynthesisUtterance(
            `D√©tect√©: ${topPrediction.class} avec ${Math.round(topPrediction.score * 100)}% de confiance`
          );
          window.speechSynthesis.speak(speech);
        }
      }

      // Nettoyer le canvas pour le nouveau rendu
      ctx.clearRect(0, 0, canvas.width, canvas.height);
      
      // Appliquer les filtres visuels si n√©cessaire
      if (brightness !== 100 || zoomLevel !== 1) {
        ctx.filter = `brightness(${brightness}%)`;
        ctx.save();
        
        if (zoomLevel !== 1) {
          ctx.translate(canvas.width / 2, canvas.height / 2);
          ctx.scale(zoomLevel, zoomLevel);
          ctx.translate(-canvas.width / 2, -canvas.height / 2);
        }
        
        // Dessiner la vid√©o avec filtres
        ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
        ctx.restore();
        ctx.filter = 'none';
      }
      
      // Dessiner les rectangles et √©tiquettes des objets d√©tect√©s
      enhancedPredictions.forEach(prediction => {
        const [x, y, width, height] = prediction.bbox;
        const isSelected = selectedObject && selectedObject.class === prediction.class;

        // Style du rectangle
        ctx.strokeStyle = isSelected ? '#FF3366' : '#00FFFF';
        ctx.lineWidth = isSelected ? 4 : 2;
        ctx.lineJoin = 'round';

        // Dessiner le rectangle (avec arrondis si disponible)
        if (typeof ctx.roundRect === 'function') {
          ctx.beginPath();
          ctx.roundRect(x, y, width, height, 5);
          ctx.stroke();
        } else {
          ctx.strokeRect(x, y, width, height);
        }

               // Cr√©er √©tiquette avec info-bulle pour chaque objet d√©tect√©
        const text = `${prediction.icon} ${prediction.class} : ${(prediction.score * 100).toFixed(0)}%`;
        const textWidth = ctx.measureText(text).width + 20;
        const bubbleHeight = 30;

        ctx.fillStyle = isSelected ? 'rgba(255, 51, 102, 0.8)' : 'rgba(0, 0, 0, 0.7)';

        // Cr√©er bulle d'arri√®re-plan pour le texte
        ctx.beginPath();
        if (typeof ctx.roundRect === 'function') {
          ctx.roundRect(
            x - 5,
            y > bubbleHeight + 10 ? y - bubbleHeight - 5 : y + height + 5,
            textWidth,
            bubbleHeight,
            5
          );
        } else {
          ctx.fillRect(
            x - 5,
            y > bubbleHeight + 10 ? y - bubbleHeight - 5 : y + height + 5,
            textWidth,
            bubbleHeight
          );
        }
        ctx.fill();

        // Ajouter le texte de l'√©tiquette
        ctx.fillStyle = '#FFFFFF';
        ctx.font = 'bold 16px Arial';
        ctx.fillText(
          text,
          x + 5,
          y > bubbleHeight + 10 ? y - bubbleHeight / 2 - 5 : y + height + bubbleHeight / 2 + 5
        );
      });
      
    } catch (error) {
      console.error("Erreur pendant la d√©tection:", error);
    }

    // Boucle de d√©tection continue
    requestAnimationFrame(detectFrame);
  }, [isDetecting, selectedObject, zoomLevel, brightness, audioEnabled, detectionInterval]);

  // D√©marrer la d√©tection une fois le mod√®le charg√©
  useEffect(() => {
    if (!loadingModel) {
      detectFrame();
    }
  }, [detectFrame, loadingModel]);

  /**
   * Capture une photo depuis le flux webcam
   */
  const capturePhoto = () => {
    if (webcamRef.current) {
      const imageSrc = webcamRef.current.getScreenshot();
      if (imageSrc) {
        setCapturedImage(imageSrc);
        setIsDetecting(false);

        if (audioEnabled) {
          window.speechSynthesis.cancel();
          const speech = new SpeechSynthesisUtterance("Photo captur√©e");
          window.speechSynthesis.speak(speech);
        }
      }
    }
  };

  /**
   * Analyse une image captur√©e ou charg√©e
   */
  const analyzeImage = async () => {
    if (!capturedImage || !modelRef.current?.cocoModel) return;

    try {
      const img = new Image();
      img.crossOrigin = "anonymous"; // √âvite les erreurs CORS
      img.src = capturedImage;

      // Attendre que l'image soit charg√©e
      await new Promise(resolve => { img.onload = resolve; });

      // Analyser l'image avec le mod√®le
      const rawPredictions = await modelRef.current.cocoModel.detect(img, 10);
      const enhancedPredictions = enrichPredictions(rawPredictions.filter(p => p.score > 0.5));

      setPredictions(enhancedPredictions);

      // Dessiner l'image et les d√©tections sur le canvas
      const canvas = canvasRef.current;
      const ctx = canvas.getContext('2d');

      canvas.width = img.width;
      canvas.height = img.height;

      ctx.clearRect(0, 0, canvas.width, canvas.height);
      ctx.drawImage(img, 0, 0);

      // Dessiner les rectangles de d√©tection sur l'image
      enhancedPredictions.forEach(prediction => {
        const [x, y, width, height] = prediction.bbox;

        ctx.strokeStyle = '#00FFFF';
        ctx.lineWidth = 2;
        ctx.lineJoin = 'round';
        ctx.strokeRect(x, y, width, height);

        ctx.fillStyle = 'rgba(0, 0, 0, 0.7)';
        ctx.fillRect(x, y > 20 ? y - 25 : y + height, width, 25);

        ctx.fillStyle = '#FFFFFF';
        ctx.font = '16px Arial';
        ctx.fillText(
          `${prediction.class} ${(prediction.score * 100).toFixed(0)}%`,
          x + 5,
          y > 20 ? y - 7 : y + height + 18
        );
      });
    } catch (error) {
      console.error("Erreur lors de l'analyse de l'image:", error);
      setErrorMessage("Erreur lors de l'analyse de l'image");
    }
  };

  /**
   * Retour au mode de d√©tection en direct
   */
  const resumeLiveDetection = () => {
    setCapturedImage(null);
    setIsDetecting(true);
  };

  /**
   * Change la cam√©ra (avant/arri√®re sur mobile)
   */
  const switchCamera = () => {
    setCameraFacingMode(prev => (prev === "user" ? "environment" : "user"));
  };

  return (
    <div className={`analyse-container ${darkMode ? 'dark-mode' : 'light-mode'}`}>
      {/* Overlay de chargement */}
      {loadingModel && (
        <motion.div
          className="loading-overlay"
          initial={{ opacity: 0 }}
          animate={{ opacity: 1 }}
          exit={{ opacity: 0 }}
          aria-live="polite"
        >
          <div className="loader" aria-hidden="true"></div>
          <h2>Chargement des mod√®les d'IA...</h2>
          <p>Pr√©paration des r√©seaux de neurones et bases de connaissances</p>
        </motion.div>
      )}

      {/* Message d'erreur */}
      {errorMessage && (
        <motion.div
          className="error-message"
          initial={{ opacity: 0, y: -50 }}
          animate={{ opacity: 1, y: 0 }}
          exit={{ opacity: 0, y: -50 }}
          role="alert"
        >
          <FaInfoCircle size={24} aria-hidden="true" />
          <p>{errorMessage}</p>
          <button onClick={() => setErrorMessage(null)} aria-label="Fermer le message d'erreur">Fermer</button>
        </motion.div>
      )}

      <div className="main-content">
        <div className="camera-container">
          <div className="camera-view" aria-live="polite" aria-label="Flux vid√©o avec d√©tection d'objets">
            {!capturedImage ? (
              <>
                <Webcam
                  ref={webcamRef}
                  audio={false}
                  screenshotFormat="image/jpeg"
                  videoConstraints={{ facingMode: cameraFacingMode, aspectRatio: 4 / 3 }}
                  className="webcam"
                  style={{ filter: `brightness(${brightness}%)`, transform: `scale(${zoomLevel})` }}
                />
                <canvas ref={canvasRef} className="detection-canvas" />
              </>
            ) : (
              <div className="captured-image-container">
                <img src={capturedImage} alt="Image captur√©e" className="captured-image" />
                <canvas ref={canvasRef} className="detection-canvas" />
              </div>
            )}

            {/* Overlay de d√©tail pour l'objet s√©lectionn√© */}
            {selectedObject && (
              <motion.div
                className="object-detail-overlay"
                initial={{ opacity: 0, y: 20 }}
                animate={{ opacity: 1, y: 0 }}
                exit={{ opacity: 0, y: 20 }}
                role="dialog"
                aria-modal="true"
                aria-labelledby="object-detail-title"
              >
                <div className="object-detail-card">
                  <div className="object-header">
                    <div className="object-title">
                      <span className="object-icon" aria-hidden="true">{selectedObject.icon}</span>
                      <h3 id="object-detail-title">{selectedObject.class}</h3>
                    </div>
                    <button 
                      className="close-btn" 
                      onClick={() => setSelectedObject(null)}
                      aria-label="Fermer les d√©tails"
                    >√ó</button>
                  </div>

                  <div className="object-body">
                    <div className="confidence-meter" 
                      aria-label={`Niveau de confiance: ${(selectedObject.score * 100).toFixed(1)}%`}
                    >
                      <span>Confiance: {(selectedObject.score * 100).toFixed(1)}%</span>
                      <div className="progress-bar" role="progressbar" 
                        aria-valuenow={(selectedObject.score * 100).toFixed(1)}
                        aria-valuemin="0"
                        aria-valuemax="100"
                      >
                        <div
                          className="progress"
                          style={{
                            width: `${selectedObject.score * 100}%`,
                            backgroundColor:
                              selectedObject.score > 0.7
                                ? '#4CAF50'
                                : selectedObject.score > 0.5
                                  ? '#FFC107'
                                  : '#F44336'
                          }}
                        ></div>
                      </div>
                    </div>

                    <div className="detail-section">
                      <h4>Caract√©ristiques</h4>
                      <p>{selectedObject.caracteristiques}</p>
                    </div>

                    <div className="detail-section">
                      <h4>Utilisation</h4>
                      <p>{selectedObject.utilisation}</p>
                    </div>

                    <div className="detail-columns">
                      <div className="detail-column">
                        <h4>Cat√©gories</h4>
                        <ul>
                          {selectedObject.categories.map((cat, i) => (
                            <li key={i}>{cat}</li>
                          ))}
                        </ul>
                      </div>

                      <div className="detail-column">
                        <h4>Mat√©riaux</h4>
                        <ul>
                          {selectedObject.materiaux.map((mat, i) => (
                            <li key={i}>{mat}</li>
                          ))}
                        </ul>
                      </div>
                    </div>

                    <div className="detail-section">
                      <h4>Dimensions Moyennes</h4>
                      <pre style={{ whiteSpace: 'pre-wrap' }}>
                        {JSON.stringify(selectedObject.dimensionsMoyennes, null, 2)}
                      </pre>
                      <p><strong>Poids estim√©:</strong> {selectedObject.poidsEstime}</p>
                    </div>

                    <div className="detail-section">
                      <h4>Analyse de la taille sur l'image</h4>
                      <pre style={{ whiteSpace: 'pre-wrap' }}>
                        {selectedObject.analyseComplete
                          ? JSON.stringify(selectedObject.analyseComplete, null, 2)
                          : 'Non disponible'}
                      </pre>
                    </div>

                    <div className="detail-section">
                      <h4>Analyse du texte potentiel</h4>
                      <p><strong>Potentiel:</strong> {selectedObject.analyseTexte?.potentiel || 'Non sp√©cifi√©'}</p>
                      <p><strong>Zone disponible:</strong> {selectedObject.analyseTexte?.zoneTexte || 'Non sp√©cifi√©e'}</p>
                    </div>

                    <div className="detail-section">
                      <h4>Histoire</h4>
                      <p>{selectedObject.histoire}</p>
                    </div>

                    <div className="detail-section conseil">
                      <h4>Conseil</h4>
                      <p>{selectedObject.conseil}</p>
                    </div>
                  </div>
                </div>
              </motion.div>
            )}
          </div>

          {/* Barre d'outils de cam√©ra */}
          <div className="camera-toolbar" role="toolbar" aria-label="Contr√¥les de cam√©ra">
            <motion.button
              whileTap={{ scale: 0.9 }}
              className="tool-button"
              onClick={switchCamera}
              title="Changer de cam√©ra"
              aria-label="Changer entre cam√©ra avant et arri√®re"
            >
              <FaExchangeAlt />
            </motion.button>

            <motion.button
              whileTap={{ scale: 0.9 }}
              className="tool-button"
              onClick={() => setZoomLevel(prev => Math.max(1, prev - 0.1))}
              disabled={zoomLevel <= 1}
              title="Zoom arri√®re"
              aria-label="Zoom arri√®re"
            >
              <BsZoomOut />
            </motion.button>

            <motion.button
              whileTap={{ scale: 0.9 }}
              className={`tool-button ${!capturedImage ? "primary" : ""}`}
              onClick={capturedImage ? analyzeImage : capturePhoto}
              title={capturedImage ? "Analyser l'image" : "Prendre une photo"}
              aria-label={capturedImage ? "Analyser l'image" : "Prendre une photo"}
            >
              <FaCamera />
            </motion.button>

            <motion.button
              whileTap={{ scale: 0.9 }}
              className="tool-button"
              onClick={() => setZoomLevel(prev => Math.min(3, prev + 0.1))}
              disabled={zoomLevel >= 3}
              title="Zoom avant"
              aria-label="Zoom avant"
            >
              <BsZoomIn />
            </motion.button>

            <label className="tool-button" title="Charger une image" aria-label="Charger une image">
              <MdPhotoLibrary />
              <input
                type="file"
                accept="image/*"
                style={{ display: 'none' }}
                onChange={e => {
                  const file = e.target.files?.[0];
                  if (file) {
                    const reader = new FileReader();
                    reader.onloadend = () => {
                      setCapturedImage(reader.result);
                      setIsDetecting(false);
                      setTimeout(() => analyzeImage(), 100);
                    };
                    reader.readAsDataURL(file);
                  }
                }}
              />
            </label>
          </div>

          {/* Contr√¥les pour l'image captur√©e */}
          {capturedImage && (
            <div className="capture-controls">
              <motion.button
                whileTap={{ scale: 0.9 }}
                onClick={resumeLiveDetection}
                className="control-button"
                aria-label="Retour √† la cam√©ra en direct"
              >
                Retour √† la cam√©ra
              </motion.button>

              <motion.button
                whileTap={{ scale: 0.9 }}
                onClick={() => {
                  if (!capturedImage) return;
                  const link = document.createElement('a');
                  link.href = capturedImage;
                  link.download = `detected-objects-${new Date().toISOString()}.jpg`;
                  document.body.appendChild(link);
                  link.click();
                  document.body.removeChild(link);
                  if (audioEnabled) {
                    window.speechSynthesis.cancel();
                    const speech = new SpeechSynthesisUtterance("Image sauvegard√©e dans votre galerie");
                    window.speechSynthesis.speak(speech);
                  }
                }}
                className="control-button"
                aria-label="Sauvegarder l'image"
              >
                <FaSave /> Sauvegarder l'image
              </motion.button>
            </div>
          )}
        </div>

        {/* Liste des objets d√©tect√©s */}
        <div className="detected-list-container">
          <h2>Objets d√©tect√©s</h2>
          {predictions.length === 0 && !loadingModel && <p>En attente de d√©tection...</p>}

          <ul className="detected-list" role="listbox" aria-label="Liste des objets d√©tect√©s">
            <AnimatePresence>
              {predictions.map((item, index) => {
                const isSelected = selectedObject?.class === item.class;
                return (
                  <motion.li
                    key={`${item.class}-${index}`}
                    className={`detected-item ${isSelected ? "selected" : ""}`}
                    onClick={() => setSelectedObject(isSelected ? null : item)}
                    initial={{ opacity: 0, x: -20 }}
                    animate={{ opacity: 1, x: 0 }}
                    exit={{ opacity: 0 }}
                    whileHover={{ scale: 1.05, backgroundColor: '#222' }}
                    role="option"
                    aria-selected={isSelected}
                    tabIndex={0}
                    onKeyDown={(e) => {
                      if (e.key === 'Enter' || e.key === ' ') {
                        e.preventDefault();
                        setSelectedObject(isSelected ? null : item);
                      }
                    }}
                  >
                    <span className="item-icon" aria-hidden="true">{item.icon}</span>
                    <div className="item-text">
                      <strong>{item.class}</strong>
                      <span>{(item.score * 100).toFixed(1)}%</span>
                    </div>
                  </motion.li>
                );
              })}
            </AnimatePresence>
          </ul>
        </div>

        {/* Param√®tres */}
        <div className="settings-section">
          <h3>Param√®tres</h3>
          <div className="setting-item">
            <label>
              <input
                type="checkbox"
                checked={darkMode}
                onChange={() => setDarkMode(!darkMode)}
              /> Mode sombre
            </label>
          </div>
          <div className="setting-item">
            <label>
              <input
                type="checkbox"
                checked={audioEnabled}
                onChange={() => setAudioEnabled(!audioEnabled)}
              /> Commentaires audio activ√©s
            </label>
          </div>
          <div className="setting-item">
            <label>
              Mode d√©tection:&nbsp;
              <select
                value={detectionMode}
                onChange={(e) => setDetectionMode(e.target.value)}
              >
                <option value="normal">Normal</option>
                <option value="fast">Rapide</option>
                <option value="detail">D√©taill√©</option>
              </select>
            </label>
          </div>
          <div className="setting-item">
            <label>
              Luminosit√©:&nbsp;
              <input
                type="range"
                min="50"
                max="150"
                value={brightness}
                onChange={(e) => setBrightness(Number(e.target.value))}
                aria-valuemin="50"
                aria-valuemax="150"
                aria-valuenow={brightness}
              />&nbsp;{brightness}%
            </label>
          </div>
          <motion.button
            className="settings-toggle-btn"
            onClick={() => setShowSettings(!showSettings)}
            whileTap={{ scale: 0.9 }}
            aria-expanded={showSettings}
            aria-controls="advanced-settings"
          >
            <FaCog /> {showSettings ? "Cacher" : "Afficher"} param√®tres avanc√©s
          </motion.button>

          {/* Options avanc√©es */}
          <AnimatePresence>
            {showSettings && (
              <motion.div
                id="advanced-settings"
                className="settings-advanced"
                initial={{ opacity: 0, height: 0 }}
                animate={{ opacity: 1, height: "auto" }}
                exit={{ opacity: 0, height: 0 }}
              >
                <div className="setting-item">
                  <label>
                    <input
                      type="checkbox"
                      checked={enableCloudAnalysis}
                      onChange={() => setEnableCloudAnalysis(!enableCloudAnalysis)}
                      disabled
                    /> Analyse dans le cloud (bient√¥t disponible)
                  </label>
                  <small className="coming-soon" aria-label="Fonctionnalit√© √† venir">‚ö†Ô∏è</small>
                </div>
                <div className="setting-item">
                  <label>
                    <input
                      type="checkbox"
                      checked={audioEnabled}
                      onChange={() => setAudioEnabled(!audioEnabled)}
                    /> {audioEnabled ? <FaVolumeUp /> : <FaVolumeMute />} Commentaires vocaux
                  </label>
                </div>
              </motion.div>
            )}
          </AnimatePresence>
        </div>
      </div>
    </div>
  );
};

export default Analyse;

